{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14buImQ1ZguSKCCZZRvclIdslre8VIw_f",
      "authorship_tag": "ABX9TyMvDbtEbiGcbKZyIM6DJNL4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeonJaeHong/ESAA_homeworks/blob/main/12_25_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이썬 머신러닝 7-06. 군집화 실습- 고객 세그먼테이션"
      ],
      "metadata": {
        "id": "tSsCGbSJy6qe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "고객 세그먼테이션은 CRM 이나 메케팅의 중요 기반 요소로서 다양한 기준으로 고객 분류 기법\n",
        "\n",
        "*   고객 세그먼테이션의 주요 목표-> 타깃 마케팅 (고객을 여러 특성에 맞게 세분화해 그 유형에 따라 맞춤형 마케팅이나 서비스 제공) -고객 상품 구매 이력에서 출발\n",
        "\n",
        "*   고객 군집화 중요: RFM 기법 이용\n",
        "RFM 기법: Recency + Frequency + Monetary value\n"
      ],
      "metadata": {
        "id": "IUynXHdzy1Xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 세트 로딩과 데이터 클렌징"
      ],
      "metadata": {
        "id": "N_hy4gdPy4Ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "제품 주문 데이터 세트 로딩\n",
        "InvoiceNo: 주문번호, ‘C’로 시작하는 것은 취소 주문\n",
        "StockCode: 제품 코드(Item Code)\n",
        "Description: 제품 설명\n",
        "Quantity : 주문 제품 건수\n",
        "InvoiceDate: 주문 일자\n",
        "UnitPrice: 제품 단가\n",
        "CustomerID: 고객 번호\n",
        "Country: 국가명(주문 고객의 국적)"
      ],
      "metadata": {
        "id": "p1FBrsBU3ot_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "retail_df =pd.read_excel(io=\"/content/Online Retail.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "6CB5IP7lzyIk",
        "outputId": "4dc30a9f-5b85-4420-91d3-b0dadc96004c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b2f18f85d705>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mretail_df\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/Online Retail.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n\u001b[1;32m   1655\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1657\u001b[0m                         \u001b[0;34m\"Excel file format cannot be determined, you must specify \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                         \u001b[0;34m\"an engine manually.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retail_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "-GKohNTpz02k",
        "outputId": "da7dfcc3-8c2c-4519-cef4-3b1ddf5b3de5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1859ec6066ff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'retail_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "null값이 많아서 사전 정제 작업이 필요하다"
      ],
      "metadata": {
        "id": "ntj4wZIQdPyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#불린 인덱싱을 적용하여 quantity > 0, unitprice > 0, customerID가  not null인 값만 필터링\n",
        "retail_df = retail_df[retail_df['Quantity'] > 0]\n",
        "retail_df = retail_df[retail_df['UnitPrice'] > 0]\n",
        "retail_df = retail_df[retail_df['CustomerID'].notnull()]\n",
        "print(retail_df.shape)\n",
        "retail_df.isnull().sum()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "rZX-ezeFc6zK",
        "outputId": "deff9249-4f8b-413e-8edc-f1e6a7cc0a2f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-65c5b2ef5d4d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#불린 인덱싱을 적용하여 quantity > 0, unitprice > 0, customerID가  not null인 값만 필터링\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mretail_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Quantity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mretail_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UnitPrice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mretail_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CustomerID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretail_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retail_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retail_df['Country'].value_counts()[:5]"
      ],
      "metadata": {
        "id": "2cBXd2tgbeBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 영국이 대다수를 차지하므로 다른 국가의 데이터는 모두 제외\n",
        "\n",
        "retail_df = retail_df[retail_df['Country'] == 'United Kingdom']\n",
        "print(retail_df.shape)"
      ],
      "metadata": {
        "id": "J635eX8rdAId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종 데이터가 354321건으로 준 것을 확인\n",
        "\n"
      ],
      "metadata": {
        "id": "CbSQ4AE5dF7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM 기반 데이터 가공\n",
        "> unitprice * quantity = 주문 금액 데이터\n",
        "> customerNo도 더 편리한 식별성을 위해 float -> int"
      ],
      "metadata": {
        "id": "iGLsb9EddWih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retail_df['sale_amount'] = retail_df['Quantity'] * retail_df['UnitPrice']\n",
        "retail_df['CustomerID'] = retail_df['CustomerID'].astype(int)\n",
        "\n",
        "#top5 주문건수와 주문금액 추출\n",
        "print(retail_df['CustomerID'].value_counts().head(5))\n",
        "print(retail_df.groupby('CustomerID')['sale_amount'].sum().sort_values(ascending=False)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "sEKPWFYYdkzW",
        "outputId": "91c83ace-7674-4840-d157-0722cc05addb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3ad630f72854>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sale_amount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Quantity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UnitPrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CustomerID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CustomerID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#top5 주문건수와 주문금액 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CustomerID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'retail_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#주문번호InvoiceNo + 상품코드StockCode 레벨의 식별자로 group by 수행시\n",
        "retail_df.groupby(['InvoiceNo', 'StockCode'])['InvoiceNo'].count().mean()\n",
        "#식별자 레벨이 1에 가깝게 됨"
      ],
      "metadata": {
        "id": "GWbfMjC9doOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM 기반의 고객 세그먼테이션은 고객 레벨로 주문 기간, 주문 횟수, 주문 금액 데이터를 기반으로 해 세그먼테이션을 수행하는 것이므로 주문번호+상품코드 기준의 데이터를 고객 기준의 Recency, Frequency, Monetary value 데이터로 변경해야한다. 이를 위해서는 주문 번호 기준의 데이터를 개별 고객 기준의 데이터로 groupby 해야한다."
      ],
      "metadata": {
        "id": "7fUrIst6dyWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df의 groupby()의 multiple연산을 위해 agg() 이용\n",
        "# Recency는 InvoiceDate 칼럼의 max()에서 데이터 가공\n",
        "# Frequency는 InvoiceNo 칼럼의 count(), Monetary value는 sale_amount 칼럼의 sum()\n",
        "aggregations = {\n",
        "    'InvoiceDate':'max',\n",
        "    'InvoiceNo': 'count',\n",
        "    'sale_amount':'sum'\n",
        "}\n",
        "cust_df = retail_df.groupby('CustomerID').agg(aggregations)\n",
        "# groupby된 결과 칼럼 값을 Recency, Frequency, Monetary로 변경\n",
        "cust_df = cust_df.rename(columns = {'InvoiceDate':'Recency',\n",
        "                                    'InvoiceNo':'Frequency',\n",
        "                                    'sale_amount':'Monetary'})\n",
        "cust_df = cust_df.reset_index()\n",
        "cust_df.head(3)"
      ],
      "metadata": {
        "id": "hwEbLylOdtr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "cust_df['Recency'] = dt.datetime(2011, 12, 10) - cust_df['Recency']\n",
        "cust_df['Recency'] = cust_df['Recency'].apply(lambda x: x.days+1)\n",
        "print('cust_df 로우와 칼럼 건수는 ', cust_df.shape)\n",
        "cust_df.head(3)\n",
        ""
      ],
      "metadata": {
        "id": "8xmbJHdeeO_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM 기반 고객 세그먼테이션\n",
        "\n",
        "> 온라인 판매 데이터 set는 소매업체의 대규모 주문을 포함하고있기 때문에 이로 인해 왜곡된 데이터 분포도를 가지게 되어 군집화가 한쪽 군집에만 집중되는 현상이 발생"
      ],
      "metadata": {
        "id": "4W4RgjI6eyT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(12, 4), nrows=1, ncols=3)\n",
        "ax1.set_title('Recency Histogram')\n",
        "ax1.hist(cust_df['Recency'])\n",
        "\n",
        "ax2.set_title('Frequncy Histogram')\n",
        "ax2.hist(cust_df['Frequency'])\n",
        "\n",
        "ax3.set_title('Monetary Histogram')\n",
        "ax3.hist(cust_df['Monetary'])\n",
        "\n",
        "# 모두 왜곡된 데이터값 분포를 가지고 있으면서 특히 frequency, monetary의 경우 특정 범위에 몰려있어서 왜곡이 심하다"
      ],
      "metadata": {
        "id": "bBQgMLYqfB3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_df[['Recency', 'Frequency', 'Monetary']].describe()"
      ],
      "metadata": {
        "id": "asNmv2vFfHzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "왜곡 정도가 매우 높은 데이터 세트에 k-평균 군집을 적용하면 중심의 개수를 증가시키더라도 변별력이 떨어지는 군집화가 수행된다, 먼저 데이터 세트를 standardscaler로 평균과 표준편차를 재조정한뒤에 k-평균을 수행하겠다"
      ],
      "metadata": {
        "id": "i4CtHrJGgs_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "\n",
        "X_features = cust_df[['Recency', 'Frequency', 'Monetary']].values\n",
        "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "labels = kmeans.fit_predict(X_features_scaled)\n",
        "cust_df['cluster_label'] = labels\n",
        "\n",
        "print('실루엣 스코어는 : {0:.3f}'.format(silhouette_score(X_features_scaled, labels)))"
      ],
      "metadata": {
        "id": "5dlwjlTcg8-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#개별 군집의 실루엣 계수값과 데이터 구성알아보기\n",
        "\n",
        "def visualize_silhouette(cluster_lists, X_features):\n",
        "\n",
        "    from sklearn.datasets import make_blobs\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.cm as cm\n",
        "    import math\n",
        "\n",
        "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
        "    n_cols = len(cluster_lists)\n",
        "\n",
        "    # plt.subplots()으로 리스트에 기재된 클러스터링 만큼의 sub figures를 가지는 axs 생성\n",
        "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
        "\n",
        "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
        "    for ind, n_cluster in enumerate(cluster_lists):\n",
        "\n",
        "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산.\n",
        "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
        "        cluster_labels = clusterer.fit_predict(X_features)\n",
        "\n",
        "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
        "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
        "\n",
        "        y_lower = 10\n",
        "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
        "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
        "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
        "        axs[ind].set_ylabel(\"Cluster label\")\n",
        "        axs[ind].set_xlim([-0.1, 1])\n",
        "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
        "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
        "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현.\n",
        "        for i in range(n_cluster):\n",
        "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
        "            ith_cluster_sil_values.sort()\n",
        "\n",
        "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
        "            y_upper = y_lower + size_cluster_i\n",
        "\n",
        "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
        "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
        "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
        "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "            y_lower = y_upper + 10\n",
        "\n",
        "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IkV2zkAahCkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#군집별로 알아본 결과\n",
        "visualize_silhouette([2,3,4,5], X_features_scaled)\n",
        "visualize_kmeans_plot_multi([2,3,4,5], X_features_scaled)"
      ],
      "metadata": {
        "id": "2DRpntPNh0e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 세트의 왜곡 정도를 낮추기 위해 로그 변환 시행"
      ],
      "metadata": {
        "id": "mdSP8OP4h-cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "# RFM 칼럼에 np.log1p()로 log transformation\n",
        "cust_df['Recency_log'] = np.log1p(cust_df['Recency'])\n",
        "cust_df['Frequency_log'] = np.log1p(cust_df['Frequency'])\n",
        "cust_df['Monetary_log'] = np.log1p(cust_df['Monetary'])\n",
        "\n",
        "# Log Transformation 데이터에 standard scaler 적용\n",
        "X_features = cust_df[['Recency_log', 'Frequency_log', 'Monetary_log']].values\n",
        "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "labels = kmeans.fit_predict(X_features_scaled)\n",
        "\n",
        "cust_df['cluster_label'] = labels\n",
        "print('실루엣 스코어는 : {0:.3f}'.format(silhouette_score(X_features_scaled, labels)))\n"
      ],
      "metadata": {
        "id": "JBAy98nph33m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실루엣 스코어는 로그 변환 전보다 떨어지지만, 절대치가 중요한 것이 아니다를 앞에서 확인할 수 있었음. 어떻게 개별 군집이 어떻게 더 균일하게 나뉠수 있는지가 더 중요하다."
      ],
      "metadata": {
        "id": "YoLtz8kbiJLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "08. 텍스트 분석"
      ],
      "metadata": {
        "id": "bObpW9B5iXb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">NLP이냐 텍스트 분석이냐?\n",
        "\n",
        "NLP는 머신이 인간의 언어를 이해하고 해석하는데 더 중점을 두고 발전했으며, 텍스트 마이닝이라고도 불리는 텍스트 분석은 비정형 텍스트에서 의미 있는 정보를 추출하는것에 더 중점을 두고 발전해 왔다.\n",
        "NLP는 언어를 해석하기 위한 기계 번역, 자동으로 질문을 해석하고 답 해주는 질의응답 시스템 등의 영역에서 텍스트 분석과 차별점 있고, 텍스트 분석은 머신러닝, 언어 이해, 통계 활용해 모델 수립후 정보 추출해 bi 나 예측 분석 등 분석 작업 주로 수행한다."
      ],
      "metadata": {
        "id": "1lOtJyvFigXG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHJZGtYkiaLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}